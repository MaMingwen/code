{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iXIpiD-V6EAo"
      },
      "source": [
        "# 0 Outline\n",
        "1. Data Process Functions or Class, APIs:\n",
        "    - can input from excel or others.\n",
        "    - Output 2-D data points.\n",
        "        - 1th dimention indicates single data point(x,y,z,t,value).\n",
        "        - 2th dimention indicates the number of data points.\n",
        "    - Every data point has form (x,y,z,t,value), where x,y,z is spatial corordinate, t is temporal corordinates, and value is function(to be solved) value.\n",
        "    - be Tensor.\n",
        "    - can assign accuracy for each number.\n",
        "    - can assign whether gradient 'on' or 'off'.\n",
        "\n",
        "2. Model Functions or Class, APIs:\n",
        "    - models\n",
        "3. Tool Functions or Class, APIs:\n",
        "    - train\n",
        "    - evaulate\n",
        "4. Visualization Functions or Class, APIs:\n",
        "\n",
        "\n",
        "关于数据集的一些信息\n",
        "- **似乎**matlab产生的数据集都是边界点在前。\n",
        "    - 二维圆盘热方程为例，前56项都是边界的mesh。\n",
        "\n",
        "方程形式：\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\begin{cases}\n",
        "u_t(x,t) &= \\triangle u(x,t),\\quad t\\in[0,2],\\quad x\\in\\Omega = \\{|x|^2 \\leq 1\\} \\\\\n",
        "\\frac{\\partial u(x,t)}{\\partial \\mathbf{n}} &= u(x,t)^4 - u_0^4,\\quad x\\in \\partial\\Omega \\\\\n",
        "u(x,0) &= c.\n",
        "\\end{cases}\n",
        "\\end{aligned}\n",
        "$$\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-NCe32XM6EAr"
      },
      "source": [
        "# import modules involved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "sEpR3rCz6EAs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas\n",
        "import torch.nn as nn\n",
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY5tcRGzHvSC",
        "outputId": "b53df2ae-b54e-4be6-e728-896b5bd58c08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[((1, 2), 1), ((1, 2), 2), ((2, 3), 1), ((2, 3), 2)]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [(1,2),(2,3)]\n",
        "y = [1,2]\n",
        "list(itertools.product(x, y))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lZq_Ypmn6EAt"
      },
      "source": [
        "# Data Functions or Classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DqY6u7fJ6EAt"
      },
      "outputs": [],
      "source": [
        "class DataProcess:\n",
        "    \"\"\"\n",
        "    数据读取与预处理\n",
        "    主要是数据读取\n",
        "    流程(以Excel为例)\n",
        "    1.读取Excel表 (需要Pandas包)\n",
        "    2.把数据转换成Tensor格式\n",
        "    3.把数据变成指定形状\n",
        "        - 二维矩阵\n",
        "        - 行数代表数据点个数\n",
        "        - 每一行代表一个数据点，(x,y,z,t,value)\n",
        "    4.其它要求\n",
        "        - 区分边界点和内部点\n",
        "        - 区分训练集和验证集\n",
        "    \"\"\"\n",
        "    def __init__(self,input,output,spatial_dimension):\n",
        "        pass\n",
        "\n",
        "    def ReadFromExcel(self,filename):\n",
        "        pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IvTj2NhV6EAu"
      },
      "source": [
        "# Model Functions or Classes\n",
        "- model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WHW3MTJU6EAu"
      },
      "outputs": [],
      "source": [
        "class HeatEqModel(nn.Module):\n",
        "    \"\"\"\n",
        "    - 确定深度模型\n",
        "    - 前向函数\n",
        "    - 需要需要确定方程的系数\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hidden_size,\n",
        "        output_size,\n",
        "        depth,\n",
        "        mass_density,\n",
        "        specific_heat,\n",
        "        thermal_conductivity,\n",
        "        heat_source,\n",
        "        emissivity,\n",
        "        Stefan_Boltzmann_constant,\n",
        "        AmbientTemperature,\n",
        "        act=torch.nn.Tanh\n",
        "    ):\n",
        "        super(HeatEqModel, self).__init__()\n",
        "        \n",
        "        self.mass_density = mass_density\n",
        "        self.specific_heat = specific_heat\n",
        "        self.thermal_conductivity = thermal_conductivity\n",
        "        self.heat_source = heat_source\n",
        "        self.emissivity = emissivity\n",
        "        self.Stefan_Boltzmann_constant = Stefan_Boltzmann_constant\n",
        "        self.AmbientTemperature = AmbientTemperature\n",
        "\n",
        "        layers = [('input', torch.nn.Linear(input_size, hidden_size))]\n",
        "        layers.append(('input_activation', act()))\n",
        "        for i in range(depth): \n",
        "            layers.append(\n",
        "                ('hidden_%d' % i, torch.nn.Linear(hidden_size, hidden_size))\n",
        "            )\n",
        "            layers.append(('activation_%d' % i, act()))\n",
        "        layers.append(('output', torch.nn.Linear(hidden_size, output_size)))\n",
        "\n",
        "        layerDict = collections.OrderedDict(layers)\n",
        "        self.layers = torch.nn.Sequential(layerDict)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "STjQeo6C6EAv"
      },
      "source": [
        "# Util Functions or Classes\n",
        "- train\n",
        "- evalute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RndQHW9vkcED",
        "outputId": "4b4477ec-4f6c-4f51-daa3-695385b6e0d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "-YlxlhFd6EAv"
      },
      "outputs": [],
      "source": [
        "class Util:\n",
        "    \"\"\"\n",
        "    包括但不限于：\n",
        "    - 数据的处理过程\n",
        "      - 数据类型 long float\n",
        "      - 数据存储位置cpu or gpu\n",
        "    - 模型的实例化\n",
        "    - 定义损失函数\n",
        "    - 定义训练过程\n",
        "    - 定义evaluate过程\n",
        "    - \n",
        "    \"\"\"\n",
        "    def __init__(self,xy_boundary,xy_in,t,Data = None):\n",
        "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "        self.device = device\n",
        "        self.xy_boudnary = xy_boundary.to(device) # 边界点在前。\n",
        "        self.xy_in = xy_in.to(device)\n",
        "        self.xy = torch.cat((xy_boundary,xy_in),dim=0).to(device)\n",
        "        self.t = t.to(device) # 从小到大。2D\n",
        "        self.data = Data # Data可以视作一张表。\n",
        "\n",
        "        self.model = HeatEqModel(\n",
        "            input_size=3,\n",
        "            hidden_size=20,\n",
        "            output_size=1,\n",
        "            depth=4,\n",
        "            mass_density=7.87,\n",
        "            specific_heat=0.44,\n",
        "            thermal_conductivity=76.2,\n",
        "            heat_source=0.,\n",
        "            emissivity=0.1,\n",
        "            Stefan_Boltzmann_constant=5.6703*10**(-8),\n",
        "            AmbientTemperature = 300.,\n",
        "            act=torch.nn.Tanh\n",
        "        ).to(device)\n",
        "        \n",
        "        # 处理数据\n",
        "        # 边界值点，空间坐标和时间坐标合并成一个二维张量。\n",
        "        self.boundary = self.xy_boudnary.detach().clone().to(device)\n",
        "        self.t_boundary = torch.full((self.xy_boudnary.shape[0],1),self.t[0][0].item()).to(device)\n",
        "        for i in range(self.t.shape[0] - 1):\n",
        "            self.boundary = torch.cat((self.boundary,self.xy_boudnary),dim=0)\n",
        "            ti = torch.full((self.xy_boudnary.shape[0],1),self.t[i+1][0].item()).to(torch.float).to(device)\n",
        "            self.t_boundary = torch.cat((self.t_boundary,ti),dim=0)\n",
        "\n",
        "        self.AmbientTemperature_boundary = torch.full((self.boundary.shape[0],1),\n",
        "                                                      self.model.AmbientTemperature).to(torch.float).to(device)\n",
        "\n",
        "        self.boundary = torch.cat((self.boundary,self.t_boundary),dim = 1)\n",
        "\n",
        "\n",
        "        # 初值点，\n",
        "        self.initial = self.xy.detach().clone().to(device)\n",
        "        self.t0 = torch.full((self.xy.shape[0],1),0).to(device)\n",
        "\n",
        "        self.initial = torch.cat((self.initial,self.t0),dim=1)\n",
        "        self.initial.requires_grad_()\n",
        "\n",
        "        # 内部点，\n",
        "        # 先把self.xy,self.t变成1D.\n",
        "        # 再用itertools.product求卡式积。\n",
        "        self.In = self.xy_in.detach().clone()\n",
        "        t_temporal = torch.full((self.xy_in.shape[0],1),self.t[0][0].item()).to(device)\n",
        "        for i in range(self.t.shape[0] - 1):\n",
        "            t_temporal = torch.cat((t_temporal,\n",
        "                                   torch.full((self.xy_in.shape[0],1),self.t[i+1][0].item()).to(device)),\n",
        "                                   dim = 0).to(device)\n",
        "            self.In = torch.cat((self.In,self.xy_in.detach().clone()),dim=0).to(device)\n",
        "        self.In = torch.cat((self.In,t_temporal),dim = 1).to(device)\n",
        "        self.In.requires_grad_()\n",
        "        \n",
        "        self.criterion = torch.nn.MSELoss()\n",
        "        self.iter = 1\n",
        "        \n",
        "        self.optimizer = torch.optim.LBFGS(\n",
        "            self.model.parameters(), \n",
        "            lr=1.0, \n",
        "            max_iter=50000, \n",
        "            max_eval=50000, \n",
        "            history_size=50,\n",
        "            tolerance_grad=1e-5, \n",
        "            tolerance_change=1.0 * np.finfo(float).eps\n",
        "        )\n",
        "        \n",
        "        self.adam = torch.optim.Adam(self.model.parameters())\n",
        "        \n",
        "    def loss_func(self):\n",
        "        self.adam.zero_grad()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # 初边值条件产生的loss_data = loss_boundary + loss_ini.\n",
        "\n",
        "        # loss_boundary MSE()($\\triangle T \\cdot \\vector{x} + \\epsilon \\sigma (T^4 - T_{\\infty}^4)$ - 0).        \n",
        "        y_predBoudnary = self.model(self.boundary)\n",
        "\n",
        "        dy_predBoundary_dx = torch.autograd.grad(inputs=self.boundary, outputs=y_predBoudnary,\n",
        "                                                 grad_outputs=torch.ones_like(y_predBoudnary),\n",
        "                                                 retain_graph=True,\n",
        "                                                 create_graph=True)[0][:,0].unsqueeze(1)\n",
        "        \n",
        "        dy_predBoundary_dy = torch.autograd.grad(inputs=self.boundary, outputs=y_predBoudnary,\n",
        "                                                 grad_outputs=torch.ones_like(y_predBoudnary),\n",
        "                                                 retain_graph=True,\n",
        "                                                 create_graph=True)[0][:,1].unsqueeze(1)\n",
        "        \n",
        "        Nabla_y_predBoundary = torch.cat((dy_predBoundary_dx,dy_predBoundary_dy),\n",
        "                                         dim = 1)\n",
        "        \n",
        "        NormalVector = self.boundary[:,0:2]\n",
        "        #print(f\"Nabla_y_predBoundary{Nabla_y_predBoundary}\")\n",
        "        #print(f\"NormalVector{NormalVector}\")\n",
        "        dy_dn = torch.sum(Nabla_y_predBoundary * NormalVector,dim=1).unsqueeze(1)\n",
        "\n",
        "        #print(\"\\nloss_boundary:\\n\")\n",
        "        #print(f\"self.model.Stefan_Boltzmann_constant * self.model.emissivity * self.AmbientTemperature_boundary**4{self.model.Stefan_Boltzmann_constant * self.model.emissivity * self.AmbientTemperature_boundary**4}\")\n",
        "        #print(f\"dy_dn + y_predBoudnary**4 * self.model.Stefan_Boltzmann_constant * self.model.emissivity{dy_dn + y_predBoudnary**4 * self.model.Stefan_Boltzmann_constant * self.model.emissivity}\")\n",
        "        #print(f\"dy_dn{dy_dn}\")\n",
        "        #print(f\"y_predBoudnary{y_predBoudnary}\")\n",
        "        #print(f\"self.model.Stefan_Boltzmann_constant{self.model.Stefan_Boltzmann_constant}\")\n",
        "        #print(f\"self.model.emissivity{self.model.emissivity}\")\n",
        "        # loss_boundary MSE()($\\triangle T \\cdot \\vector{x} + \\epsilon \\sigma (T^4 - T_{\\infty}^4)$ - 0).Sefan_Boltzmann_constant\n",
        "        loss_boundary = self.criterion(\n",
        "                        self.model.Stefan_Boltzmann_constant * self.model.emissivity * self.AmbientTemperature_boundary**4,\n",
        "                        dy_dn + y_predBoudnary**4 * self.model.Stefan_Boltzmann_constant * self.model.emissivity\n",
        "                        )\n",
        "        \n",
        "        y_predIni = self.model(self.initial)\n",
        "\n",
        "        # loss_ini = MSE()(y_predIni,0)\n",
        "        #print(\"\\n loss_ini\\n\")\n",
        "        #print(f\"y_predIni{y_predIni}\")\n",
        "        #print(f\"torch.full((y_predIni.shape[0],1),0).to(torch.float32){torch.full((y_predIni.shape[0],1),0).to(torch.float32)}\")\n",
        "        loss_ini = self.criterion(y_predIni,torch.full((y_predIni.shape[0],1),0).to(torch.float32).to(self.device))\n",
        "\n",
        "\n",
        "        loss_data = loss_ini + loss_boundary\n",
        "\n",
        "        # loss_pde = MSE()(\\rho c \\frac{\\partial T}{\\partial t} - k\\triangle T = Q, 0).\n",
        "        y_predIn = self.model(self.In)\n",
        "\n",
        "\n",
        "        dy_predIn_dx = torch.autograd.grad(inputs=self.In, outputs=y_predIn,\n",
        "                                                 grad_outputs=torch.ones_like(y_predIn),\n",
        "                                                 retain_graph=True,\n",
        "                                                 create_graph=True)[0][:,0].unsqueeze(1)\n",
        "        \n",
        "        dy_predIn_dy = torch.autograd.grad(inputs=self.In, outputs=y_predIn,\n",
        "                                                 grad_outputs=torch.ones_like(y_predIn),\n",
        "                                                 retain_graph=True,\n",
        "                                                 create_graph=True)[0][:,1].unsqueeze(1)\n",
        "        dy_predIn_dt = torch.autograd.grad(inputs=self.In, outputs=y_predIn,\n",
        "                                                 grad_outputs=torch.ones_like(y_predIn),\n",
        "                                                 retain_graph=True,\n",
        "                                                 create_graph=True)[0][:,2].unsqueeze(1)\n",
        "\n",
        "        dy_predIn_dxdx = torch.autograd.grad(inputs=self.In, outputs=dy_predIn_dx,\n",
        "                                                 grad_outputs=torch.ones_like(dy_predIn_dx),\n",
        "                                                 retain_graph=True,\n",
        "                                                 create_graph=True)[0][:,0].unsqueeze(1)\n",
        "        \n",
        "        dy_predIn_dydy = torch.autograd.grad(inputs=self.In, outputs=dy_predIn_dy,\n",
        "                                                 grad_outputs=torch.ones_like(dy_predIn_dy),\n",
        "                                                 retain_graph=True,\n",
        "                                                 create_graph=True)[0][:,1].unsqueeze(1)\n",
        "        \n",
        "        #print(\"\\n loss pde \\n\")\n",
        "        #print(f\"dy_predIn_dt*self.model.specific_heat*self.model.mass_density{dy_predIn_dt*self.model.specific_heat*self.model.mass_density}\")\n",
        "        #print(f\"self.model.thermal_conductivity*(dy_predIn_dxdx + dy_predIn_dydy{self.model.thermal_conductivity*(dy_predIn_dxdx + dy_predIn_dydy)}\")\n",
        "        loss_pde = self.criterion(dy_predIn_dt*self.model.specific_heat*self.model.mass_density,\n",
        "                                  self.model.thermal_conductivity*(dy_predIn_dxdx + dy_predIn_dydy)\n",
        "                                  )\n",
        "\n",
        "        loss = loss_pde + loss_data\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        if self.iter % 100 == 0: \n",
        "            print(self.iter, loss.item())\n",
        "        self.iter = self.iter + 1\n",
        "        return loss\n",
        "    \n",
        "    def train(self):\n",
        "        for i in range(30000):\n",
        "            self.adam.step(self.loss_func)\n",
        "        self.optimizer.step(self.loss_func)\n",
        "    \n",
        "    def eval_(self):\n",
        "        self.model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "io = \"..\\graduate\\matlab_heatEq\\二维圆盘数据.xlsx\"\n",
        "data = pandas.read_excel(io)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "xy = pandas.DataFrame(data,columns = ['x','y'])\n",
        "t = np.arange(0,2.01,0.01)\n",
        "tlist = np.expand_dims(t, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "xy = xy.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "xy_boundary = xy[0:56,0:2]\n",
        "xy_in = xy[56::,0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.0000e+00, -1.2246e-16],\n",
              "        [ 6.1232e-17, -1.0000e+00],\n",
              "        [ 1.0000e+00,  0.0000e+00],\n",
              "        [-1.8370e-16,  1.0000e+00],\n",
              "        [-9.9370e-01, -1.1210e-01],\n",
              "        [-9.7490e-01, -2.2265e-01],\n",
              "        [-9.4387e-01, -3.3033e-01],\n",
              "        [-9.0099e-01, -4.3384e-01],\n",
              "        [-8.4680e-01, -5.3192e-01],\n",
              "        [-7.8191e-01, -6.2339e-01],\n",
              "        [-7.0711e-01, -7.0711e-01],\n",
              "        [-6.2339e-01, -7.8191e-01],\n",
              "        [-5.3192e-01, -8.4680e-01],\n",
              "        [-4.3384e-01, -9.0099e-01],\n",
              "        [-3.3033e-01, -9.4387e-01],\n",
              "        [-2.2265e-01, -9.7490e-01],\n",
              "        [-1.1210e-01, -9.9370e-01],\n",
              "        [-1.1210e-01,  9.9370e-01],\n",
              "        [-2.2265e-01,  9.7490e-01],\n",
              "        [-3.3033e-01,  9.4387e-01],\n",
              "        [-4.3384e-01,  9.0099e-01],\n",
              "        [-5.3192e-01,  8.4680e-01],\n",
              "        [-6.2339e-01,  7.8191e-01],\n",
              "        [-7.0711e-01,  7.0711e-01],\n",
              "        [-7.8191e-01,  6.2339e-01],\n",
              "        [-8.4680e-01,  5.3192e-01],\n",
              "        [-9.0099e-01,  4.3384e-01],\n",
              "        [-9.4387e-01,  3.3033e-01],\n",
              "        [-9.7490e-01,  2.2265e-01],\n",
              "        [-9.9370e-01,  1.1210e-01],\n",
              "        [ 9.9370e-01,  1.1210e-01],\n",
              "        [ 9.7490e-01,  2.2265e-01],\n",
              "        [ 9.4387e-01,  3.3033e-01],\n",
              "        [ 9.0099e-01,  4.3384e-01],\n",
              "        [ 8.4680e-01,  5.3192e-01],\n",
              "        [ 7.8191e-01,  6.2339e-01],\n",
              "        [ 7.0711e-01,  7.0711e-01],\n",
              "        [ 6.2339e-01,  7.8191e-01],\n",
              "        [ 5.3192e-01,  8.4680e-01],\n",
              "        [ 4.3384e-01,  9.0099e-01],\n",
              "        [ 3.3033e-01,  9.4387e-01],\n",
              "        [ 2.2265e-01,  9.7490e-01],\n",
              "        [ 1.1210e-01,  9.9370e-01],\n",
              "        [ 1.1210e-01, -9.9370e-01],\n",
              "        [ 2.2265e-01, -9.7490e-01],\n",
              "        [ 3.3033e-01, -9.4387e-01],\n",
              "        [ 4.3384e-01, -9.0099e-01],\n",
              "        [ 5.3192e-01, -8.4680e-01],\n",
              "        [ 6.2339e-01, -7.8191e-01],\n",
              "        [ 7.0711e-01, -7.0711e-01],\n",
              "        [ 7.8191e-01, -6.2339e-01],\n",
              "        [ 8.4680e-01, -5.3192e-01],\n",
              "        [ 9.0099e-01, -4.3384e-01],\n",
              "        [ 9.4387e-01, -3.3033e-01],\n",
              "        [ 9.7490e-01, -2.2265e-01],\n",
              "        [ 9.9370e-01, -1.1210e-01]], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_tensor = torch.from_numpy(tlist)\n",
        "xy_boundary_tensor = torch.from_numpy(xy_boundary)\n",
        "xy_in_tensor = torch.from_numpy(xy_in)\n",
        "t_tensor.requires_grad_()\n",
        "xy_in_tensor.requires_grad_()\n",
        "xy_boundary_tensor.requires_grad_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([201, 1])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 2109.3623046875\n",
            "200 2104.941650390625\n",
            "300 2101.081298828125\n",
            "400 2098.17724609375\n",
            "500 2095.4169921875\n",
            "600 2092.912353515625\n",
            "700 2090.495849609375\n",
            "800 2088.434814453125\n",
            "900 2085.985595703125\n",
            "1000 2083.652587890625\n",
            "1100 2081.482177734375\n",
            "1200 2079.415771484375\n",
            "1300 2076.938232421875\n",
            "1400 2074.7216796875\n",
            "1500 2076.53173828125\n",
            "1600 2070.18994140625\n",
            "1700 2074.620361328125\n",
            "1800 2065.556396484375\n",
            "1900 2065.746337890625\n",
            "2000 2060.768310546875\n",
            "2100 2058.3525390625\n",
            "2200 2055.775634765625\n",
            "2300 2066.603271484375\n",
            "2400 2050.52099609375\n",
            "2500 2047.781494140625\n",
            "2600 2044.94091796875\n",
            "2700 2041.914306640625\n",
            "2800 2038.9580078125\n",
            "2900 2035.6829833984375\n",
            "3000 2032.5048828125\n",
            "3100 2028.8973388671875\n",
            "3200 2026.2471923828125\n",
            "3300 2021.541259765625\n",
            "3400 2017.3861083984375\n",
            "3500 2013.3428955078125\n",
            "3600 2008.7081298828125\n",
            "3700 2004.939453125\n",
            "3800 1999.00146484375\n",
            "3900 1995.3603515625\n",
            "4000 1988.043212890625\n",
            "4100 1983.0318603515625\n",
            "4200 1975.7100830078125\n",
            "4300 1968.733642578125\n",
            "4400 1961.803466796875\n",
            "4500 1953.9381103515625\n",
            "4600 1946.1954345703125\n",
            "4700 1937.325927734375\n",
            "4800 1928.9224853515625\n",
            "4900 1918.6571044921875\n",
            "5000 1985.5240478515625\n",
            "5100 1897.64599609375\n",
            "5200 1885.8907470703125\n",
            "5300 1874.550537109375\n",
            "5400 1861.42724609375\n",
            "5500 1847.667724609375\n",
            "5600 1833.9608154296875\n",
            "5700 1818.7431640625\n",
            "5800 1803.567138671875\n",
            "5900 1786.7301025390625\n",
            "6000 1771.4638671875\n",
            "6100 1751.6016845703125\n",
            "6200 1735.5662841796875\n",
            "6300 1713.256103515625\n",
            "6400 1702.494384765625\n",
            "6500 1671.700927734375\n",
            "6600 1649.246826171875\n",
            "6700 1626.860107421875\n",
            "6800 1602.725830078125\n",
            "6900 1578.6439208984375\n",
            "7000 1552.7890625\n",
            "7100 1528.6468505859375\n",
            "7200 1499.7249755859375\n",
            "7300 1535.0948486328125\n",
            "7400 1443.592041015625\n",
            "7500 1413.843017578125\n",
            "7600 1384.2431640625\n",
            "7700 1352.9705810546875\n",
            "7800 1322.1822509765625\n",
            "7900 1289.390625\n",
            "8000 1257.362548828125\n",
            "8100 1223.2569580078125\n",
            "8200 1189.9571533203125\n",
            "8300 1154.8380126953125\n",
            "8400 1120.3646240234375\n",
            "8500 1084.6605224609375\n",
            "8600 1049.36767578125\n",
            "8700 1045.968994140625\n",
            "8800 977.0794677734375\n",
            "8900 971.336669921875\n",
            "9000 904.2349853515625\n",
            "9100 1060.2305908203125\n",
            "9200 831.225830078125\n",
            "9300 794.3422241210938\n",
            "9400 758.5309448242188\n",
            "9500 721.9742431640625\n",
            "9600 686.8770141601562\n",
            "9700 650.7095947265625\n",
            "9800 616.5780639648438\n",
            "9900 581.1278076171875\n",
            "10000 547.94873046875\n",
            "10100 513.9381713867188\n",
            "10200 481.7371826171875\n",
            "10300 452.2647399902344\n",
            "10400 419.1629638671875\n",
            "10500 397.5397033691406\n",
            "10600 360.4599914550781\n",
            "10700 333.2143249511719\n",
            "10800 356.2447204589844\n",
            "10900 281.0478820800781\n",
            "11000 259.3362731933594\n",
            "11100 234.19857788085938\n",
            "11200 213.0944366455078\n",
            "11300 192.7603302001953\n",
            "11400 174.27841186523438\n",
            "11500 174.2670440673828\n",
            "11600 141.00982666015625\n",
            "11700 129.73793029785156\n",
            "11800 113.25239562988281\n",
            "11900 101.92440032958984\n",
            "12000 90.7862777709961\n",
            "12100 81.95704650878906\n",
            "12200 73.15758514404297\n",
            "12300 66.56685638427734\n",
            "12400 59.85235595703125\n",
            "12500 55.70294952392578\n",
            "12600 50.22359848022461\n",
            "12700 63.98700714111328\n",
            "12800 43.65700149536133\n",
            "12900 41.12023162841797\n",
            "13000 40.64910125732422\n",
            "13100 37.64455032348633\n",
            "13200 94.94430541992188\n",
            "13300 35.528236389160156\n",
            "13400 34.727760314941406\n",
            "13500 34.41007614135742\n",
            "13600 33.75446701049805\n",
            "13700 33.87373733520508\n",
            "13800 33.16023635864258\n",
            "13900 34.285247802734375\n",
            "14000 32.784141540527344\n",
            "14100 44.253604888916016\n",
            "14200 32.508201599121094\n",
            "14300 75.92799377441406\n",
            "14400 32.2937126159668\n",
            "14500 47.895851135253906\n",
            "14600 32.07047653198242\n",
            "14700 168.2146759033203\n",
            "14800 31.901657104492188\n",
            "14900 31.73642921447754\n",
            "15000 32.0186653137207\n",
            "15100 31.56588363647461\n",
            "15200 46.580013275146484\n",
            "15300 31.412994384765625\n",
            "15400 31.287845611572266\n",
            "15500 31.291139602661133\n",
            "15600 31.10189437866211\n",
            "15700 31.06184196472168\n",
            "15800 31.06650161743164\n",
            "15900 30.990039825439453\n",
            "16000 83.54527282714844\n",
            "16100 30.68746566772461\n",
            "16200 35.57957077026367\n",
            "16300 30.540023803710938\n",
            "16400 93.26292419433594\n",
            "16500 30.377378463745117\n",
            "16600 33.75370407104492\n",
            "16700 30.223758697509766\n",
            "16800 31.223407745361328\n",
            "16900 30.07379913330078\n",
            "17000 30.927167892456055\n",
            "17100 29.89981460571289\n",
            "17200 29.915008544921875\n",
            "17300 31.52836036682129\n",
            "17400 32.898040771484375\n",
            "17500 29.608116149902344\n",
            "17600 38.370967864990234\n",
            "17700 29.436203002929688\n",
            "17800 45.471702575683594\n",
            "17900 29.29705047607422\n",
            "18000 31.300745010375977\n",
            "18100 29.793746948242188\n",
            "18200 30.999004364013672\n",
            "18300 29.53998565673828\n",
            "18400 28.963003158569336\n",
            "18500 30.24219512939453\n",
            "18600 29.62421226501465\n",
            "18700 28.737306594848633\n",
            "18800 29.073217391967773\n",
            "18900 38.42009735107422\n",
            "19000 28.62158203125\n",
            "19100 33.80707550048828\n",
            "19200 28.42009735107422\n",
            "19300 33.295135498046875\n",
            "19400 28.316862106323242\n",
            "19500 31.81931495666504\n",
            "19600 28.207523345947266\n",
            "19700 29.152389526367188\n",
            "19800 28.05989646911621\n",
            "19900 28.104806900024414\n",
            "20000 33.67848205566406\n",
            "20100 49.682518005371094\n",
            "20200 27.880985260009766\n",
            "20300 27.815153121948242\n",
            "20400 28.119430541992188\n",
            "20500 27.872304916381836\n",
            "20600 27.97003936767578\n",
            "20700 112.87052917480469\n",
            "20800 27.54233741760254\n",
            "20900 27.60287857055664\n",
            "21000 62.2734375\n",
            "21100 27.387802124023438\n",
            "21200 28.75876808166504\n",
            "21300 27.28311538696289\n",
            "21400 27.307355880737305\n",
            "21500 27.288192749023438\n",
            "21600 42.3141975402832\n",
            "21700 27.104759216308594\n",
            "21800 28.284021377563477\n",
            "21900 27.8780460357666\n",
            "22000 26.961692810058594\n",
            "22100 27.00579261779785\n",
            "22200 31.68557357788086\n",
            "22300 56.37247085571289\n",
            "22400 31.044919967651367\n",
            "22500 37.16748809814453\n",
            "22600 32.0774040222168\n",
            "22700 63.84468078613281\n",
            "22800 27.633119583129883\n",
            "22900 26.583559036254883\n",
            "23000 46.47549819946289\n",
            "23100 27.934518814086914\n",
            "23200 105.05381774902344\n",
            "23300 26.41873550415039\n",
            "23400 27.100061416625977\n",
            "23500 26.40743064880371\n",
            "23600 26.312240600585938\n",
            "23700 26.610292434692383\n",
            "23800 26.30925750732422\n",
            "23900 44.3096923828125\n",
            "24000 26.291898727416992\n",
            "24100 26.105484008789062\n",
            "24200 26.43567657470703\n",
            "24300 63.37239074707031\n",
            "24400 55.18817138671875\n",
            "24500 25.93265151977539\n",
            "24600 28.50510025024414\n",
            "24700 25.830581665039062\n",
            "24800 26.049949645996094\n",
            "24900 25.930418014526367\n",
            "25000 25.743024826049805\n",
            "25100 31.454811096191406\n",
            "25200 45.328670501708984\n",
            "25300 25.602779388427734\n",
            "25400 25.633678436279297\n",
            "25500 28.333648681640625\n",
            "25600 25.493453979492188\n",
            "25700 27.433971405029297\n",
            "25800 125.85369873046875\n",
            "25900 25.399215698242188\n",
            "26000 33.17443084716797\n",
            "26100 25.31334686279297\n",
            "26200 25.318456649780273\n",
            "26300 29.88730239868164\n",
            "26400 32.010379791259766\n",
            "26500 25.156278610229492\n",
            "26600 25.488807678222656\n",
            "26700 32.74076843261719\n",
            "26800 25.13330841064453\n",
            "26900 25.05512809753418\n",
            "27000 25.284914016723633\n",
            "27100 25.766786575317383\n",
            "27200 24.955669403076172\n",
            "27300 25.61024284362793\n",
            "27400 31.01329231262207\n",
            "27500 32.25196075439453\n",
            "27600 26.668912887573242\n",
            "27700 25.896759033203125\n",
            "27800 25.093673706054688\n",
            "27900 26.282184600830078\n",
            "28000 27.970678329467773\n",
            "28100 38.1692008972168\n",
            "28200 24.888858795166016\n",
            "28300 24.993574142456055\n",
            "28400 65.69308471679688\n",
            "28500 39.58851623535156\n",
            "28600 26.165233612060547\n",
            "28700 75.68692779541016\n",
            "28800 25.14745330810547\n",
            "28900 43.04806137084961\n",
            "29000 61.644676208496094\n",
            "29100 42.81938552856445\n",
            "29200 25.228147506713867\n",
            "29300 24.54722785949707\n",
            "29400 25.34455108642578\n",
            "29500 36.36231994628906\n",
            "29600 24.057212829589844\n",
            "29700 24.063108444213867\n",
            "29800 28.1073055267334\n",
            "29900 32.619407653808594\n",
            "30000 45.76768112182617\n",
            "30100 23.639291763305664\n",
            "30200 22.970191955566406\n",
            "30300 22.144155502319336\n",
            "30400 21.230220794677734\n",
            "30500 20.552698135375977\n",
            "30600 20.262514114379883\n",
            "30700 20.029706954956055\n",
            "30800 19.87285614013672\n",
            "30900 19.7285099029541\n",
            "31000 19.515779495239258\n",
            "31100 19.34633445739746\n",
            "31200 19.15202522277832\n",
            "31300 19.040225982666016\n",
            "31400 18.86014175415039\n",
            "31500 18.773752212524414\n",
            "31600 18.614765167236328\n",
            "31700 18.476137161254883\n",
            "31800 18.25168228149414\n",
            "31900 18.06314468383789\n",
            "32000 17.853282928466797\n",
            "32100 17.549663543701172\n",
            "32200 17.386112213134766\n",
            "32300 17.202932357788086\n",
            "32400 17.080787658691406\n",
            "32500 16.944019317626953\n",
            "32600 16.82050132751465\n",
            "32700 16.733699798583984\n",
            "32800 16.659332275390625\n",
            "32900 16.57261085510254\n",
            "33000 16.469205856323242\n",
            "33100 16.420286178588867\n",
            "33200 16.350975036621094\n",
            "33300 16.29395866394043\n",
            "33400 16.223318099975586\n",
            "33500 16.162918090820312\n",
            "33600 16.100257873535156\n",
            "33700 16.065582275390625\n",
            "33800 16.022117614746094\n",
            "33900 15.95946979522705\n",
            "34000 15.897631645202637\n",
            "34100 15.824355125427246\n",
            "34200 15.774697303771973\n",
            "34300 15.727571487426758\n",
            "34400 15.681682586669922\n",
            "34500 15.630480766296387\n",
            "34600 15.603087425231934\n",
            "34700 15.570213317871094\n",
            "34800 15.53589153289795\n",
            "34900 15.5077543258667\n",
            "35000 15.474008560180664\n",
            "35100 15.443167686462402\n",
            "35200 15.420244216918945\n",
            "35300 15.395505905151367\n",
            "35400 15.376036643981934\n",
            "35500 15.35616683959961\n",
            "35600 15.340202331542969\n",
            "35700 15.316062927246094\n",
            "35800 15.297143936157227\n",
            "35900 15.27200984954834\n",
            "36000 15.253645896911621\n",
            "36100 15.226733207702637\n",
            "36200 15.203248977661133\n",
            "36300 15.18040657043457\n",
            "36400 15.145766258239746\n"
          ]
        }
      ],
      "source": [
        "net = Util(xy_boundary = xy_boundary_tensor.to(torch.float32)\n",
        "           ,xy_in = xy_in_tensor.to(torch.float32)\n",
        "           ,t = t_tensor.to(torch.float32))\n",
        "net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(16.8736, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(net.loss_func())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试 测试\n",
        "## 测试数据\n",
        "\n",
        "#Data t = 0, 0.2, 0.4, 0.6, 0.8, 1\n",
        "#(0,1)    20 \n",
        "#(0,-1)\n",
        "#(-1,0)\n",
        "#(1,0)\n",
        "#(0,0)\n",
        "#(1/2,1/2)\n",
        "#(1/2,-1/2)\n",
        "#(-1/2,1/2)\n",
        "#(1/3,1/4)\n",
        "\n",
        "#t = torch.tensor([[0.0],[0.2],[0.4],[0.6],[0.8],[1.0]],dtype = torch.float,requires_grad = True)\n",
        "#xy_boundary = torch.tensor([[0.,1.],[0.,-1.],[-1.,0.],[1.,0.]],dtype = torch.float,requires_grad = True)\n",
        "#xy_in = torch.tensor([[0.,0.],[0.5,0.5],[0.5,-0.5],[-0.5,0.5],[0.33,0.25]],dtype = torch.float,requires_grad = True)\n",
        "\n",
        "\n",
        "#net = Util(xy_boundary = xy_boundary,xy_in = xy_in,t = t)\n",
        "#net.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch-3060",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
